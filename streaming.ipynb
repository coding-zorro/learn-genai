{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a model instance and stream the response from the model.\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"mistral\")\n",
    "\n",
    "chunks = []\n",
    "for chunk in model.stream(\"what color is the sky\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a string parser to parse the streamed output from the model\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "for chunk in chain.stream({\"topic\": \"Cricket\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a JSON parser to parse the streamed output from the model\n",
    "# The JSON parser will try to create a valid JSON with each chunk streamed by the model.\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = (\n",
    "    model | JsonOutputParser()\n",
    ")\n",
    "\n",
    "query =  \"\"\"output a list of the countries france, spain and japan and their populations in JSON format. \n",
    "            'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "            \"Each country should have the key `name` and `population`\"\"\"\n",
    "\n",
    "async for text in chain.astream(query):\n",
    "    print(text, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0020ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to custom parse the streamed response from the model\n",
    "\n",
    "def extract_country_names(inputs):\n",
    "    \"\"\"\n",
    "    Method to extract the names of the countries from the model response.\n",
    "    \"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "    countries = inputs[\"countries\"]\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "    country_names = [country.get(\"name\") for country in countries if isinstance(country, dict)]\n",
    "    return country_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a19df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the custom parser to extract the country names from the model response\n",
    "\n",
    "chain = model | JsonOutputParser() | extract_country_names\n",
    "async for text in chain.astream(query):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
